# ğŸ“° FakeNewsRAG  
**Retrieval-Augmented Generation Pipeline for Fake News Detection**

---

### ğŸš€ Overview

FakeNewsRAG is an **fake-news detection system** that combines  
**Retrieval-Augmented Generation (RAG)** with **Large Language Models (LLMs)**.  
Instead of treating fake-news classification as a black-box task, the system  
**mimics a human fact-checker**:  
1. It **retrieves** relevant evidence from a labeled news corpus (fake/reliable).  
2. It **summarizes** both sides using contrastive prompts.  
3. It **classifies** the new article based on which evidence aligns more closely.

This approach makes the classification **transparent and verifiable**,  
allowing users to inspect retrieved evidence, summaries, and reasoning.

---

### ğŸ’¡ Key Innovations

| Feature | Description |
|----------|-------------|
| **RAG-based Fact-Checking** | Integrates semantic retrieval (FAISS + BM25) with LLM-based reasoning. |
| **Contrastive Summaries** | Generates two opposing factual summaries â€” one from *fake* and one from *reliable* evidence â€” for side-by-side evaluation. |
| **Explainable Classification** | The modelâ€™s verdict (â€œFakeâ€ or â€œReliableâ€) is backed by textual evidence and LLM reasoning. |
| **Dynamic Cross-Encoder Re-Ranking** | Enhances retrieval accuracy using a cross-encoder (e.g., `ms-marco-MiniLM-L-6-v2`). |
| **Diversity-Aware Retrieval** | Optional Maximal Marginal Relevance (MMR) and xQuAD diversification ensure balanced evidence. |
| **Transparent UI** | Built with **Streamlit**, showing pipeline stages, live progress, and full console output. |

---

### ğŸ§  Pipeline Architecture
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 Input Article                â”‚
       â”‚   title + content                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                 1ï¸âƒ£ Evidence Retrieval
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Retrieve top-k fake & reliable evidence       â”‚
       â”‚  â€¢ FAISS dense retrieval                     â”‚
       â”‚  â€¢ BM25 lexical retrieval (optional)          â”‚
       â”‚  â€¢ Cross-encoder reranking                    â”‚
       â”‚  â€¢ MMR/xQuAD diversity                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
              2ï¸âƒ£ Contrastive Summarization
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Summarize each evidence set using the LLM     â”‚
       â”‚  â†’ Fake summary                               â”‚
       â”‚  â†’ Reliable summary                           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                 3ï¸âƒ£ Classification
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ LLM compares article vs. both summaries       â”‚
       â”‚  â†’ Prediction (Fake / Reliable)               â”‚
       â”‚  â†’ Confidence                                â”‚
       â”‚  â†’ Reasoning                                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                 4ï¸âƒ£ Streamlit Visualization
           Live stages â€¢ Console output â€¢ Verdict

         
---

### âš™ï¸ Setup & Installation

#### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/FakeNewsRAG.git
cd FakeNewsRAG
```

#### 2ï¸âƒ£ Create and activate a virtual environment

**Windows (PowerShell):**

python -m venv .venv

.venv\Scripts\activate

**macOS / Linux:**

python3 -m venv .venv

source .venv/bin/activate

#### 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

#### ğŸ§­Running the LLM Backend

The pipeline uses a local Llama and Gemma server.

Before launching the app, make sure you have a running LLM server:
```
Llama:
python -m llama_cpp.server `
  --model ./models/mistral-7b-instruct/mistral-7b-instruct-v0.2.Q4_K_M.gguf `
  --n_gpu_layers -1 --n_ctx 2048 --n_batch 256 --offload_kqv true `
  --host 127.0.0.1 --port 8011

Gemma:
python -m llama_cpp.server \
  --model /home/student/models/gemma-3-1b-it-Q4_K_M.gguf \
  --n_gpu_layers -1 \
  --n_ctx 4096 \
  --n_batch 192 \
  --offload_kqv true \
  --host 127.0.0.1 --port 8012
```

#### ğŸ§­ Running the Streamlit App

From the project root:

```
python -m streamlit run app.py
```

#### ğŸ§  UI Workflow

Paste an article title and content

Click â€œâš–ï¸ Analyzeâ€

Watch dynamic stage updates:
Loading FAISS â†’ Retrieving evidence â†’ Generating summaries â†’ Classifying article

View printed console output and final classification

âœ… RELIABLE or ğŸš© FAKE NEWS DETECTED
