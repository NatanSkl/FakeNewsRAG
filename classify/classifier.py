"""
Classification module for Fake News RAG project.

This module provides functionality to classify articles as fake or reliable
using contrastive summaries generated from retrieved evidence.
"""

from __future__ import annotations
import os
import random
from dataclasses import dataclass
from typing import Dict, Optional

import tiktoken

from common.llm_client import LocalLLM


def _trim_tokens(s: str, max_tokens: int) -> str:
    """Trim text to approximately max_tokens using tiktoken encoding."""
    s = (s or "").strip()
    if not s:
        return s

    # Use cl100k_base encoding (GPT-4 tokenizer)
    encoder = tiktoken.get_encoding("cl100k_base")
    tokens = encoder.encode(s)

    if len(tokens) <= max_tokens:
        return s

    # Truncate to max_tokens and decode back to text
    truncated_tokens = tokens[:max_tokens]
    return encoder.decode(truncated_tokens)


@dataclass
class ClassificationResult:
    """Result of article classification."""

    prediction: str  # "fake" or "reliable"
    confidence: float  # confidence score between 0 and 1
    reasoning: str  # explanation for the classification
    raw_response: str  # raw LLM response


# TODO test cases of different personalities / instructions / level of detail
# Classification prompt templates
CLASSIFICATION_SYSTEMS = [
    """
You are a news analyst specializing in fact-checking. 
Your task is to determine which of two summaries best matches a given article.
""",
    """
You are a news analyst specializing in fact-checking. 
Your task is to determine which of two summaries best matches a given article. 
The summaries were previously generated by a RAG system from a database of articles labeled by their degree of reliability.
""",
    """
You are an expert journalist. 
Your task is to determine which of two articles is the most similar to a given article. 
""",
]

# TODO add limits to these templates


def _generate_classification_template(
    naming_convention: str = "fake_reliable", promt_type: int = 0
) -> str:
    """Generate a classification template with specified naming convention and random order.

    Args:
        naming_convention: One of "fake_reliable", "type1_type2"
        promt_type: Prompt type (0 = general persona, 1 = persona with background information, 2 = new article)
    """

    # Define naming options based on convention
    if promt_type <= 1:
        noun = "SUMMARY"
    else:
        noun = "ARTICLE"

    if naming_convention == "fake_reliable":
        names = (f"FAKE NEWS", f"RELIABLE NEWS")
    elif naming_convention == "type1_type2":
        names = (f"TYPE1", f"TYPE2")
        # randomly decide which label is type1 and which is type2
        if random.random() < 0.5:
            names = (names[1], names[0])
    else:
        raise ValueError(f"Invalid naming convention")

    fake_name, reliable_name = [f"{name} {noun}" for name in names]

    # Randomly decide order (swap positions 50% of the time)
    order = random.randint(0, 1)

    template_1 = f"""
ARTICLE TO CLASSIFY
-------------------
Title: {{article_title}}
Content: {{article_content}}
"""

    if order == 0:
        template_2 = f"""
{fake_name}
{"-" * len(fake_name)}
{{fake_summary}}

{reliable_name}
{"-" * len(reliable_name)}
{{reliable_summary}}
    """
    else:
        template_2 = f"""
{reliable_name}
{"-" * len(reliable_name)}
{{reliable_summary}}

{fake_name}
{"-" * len(fake_name)}
{{fake_summary}}
    """

    if promt_type <= 1:
        template_3 = f"""
TASK
___
Based on the summaries above, determine if the article is {names[0]} or {names[1]}.

Consider:
1. Which summary better aligns with the facts in the article?
2. Are there contradictions between the article and facts mentioned in the summary?
3. Does the article contain claims that are supported by the summary?
    """
    else:
        template_3 = f"""
TASK
___
Based on the articles above, determine if the article is {names[0]} or {names[1]}.

Consider:
1. Which articles better aligns with the facts in the article?
2. Which of the articles is the most similar to the article, in style and content?"""

    template_4 = f"""
Respond with:
- Classification: [FAKE/RELIABLE]. This should be "FAKE" if the article best matches the {names[0]} {noun}, and "RELIABLE" if the article best matches the {names[1]} {noun}.
- Confidence: [0.0-1.0]   This should be a number between 0 and 1 that represents the confidence in your classification.
- Reasoning: [Brief explanation of your decision]

Format your response exactly as:
Classification: [FAKE/RELIABLE]
Confidence: [0.0-1.0]
Reasoning: [Your explanation here]
"""
    return template_1 + template_2 + template_3 + template_4


def classify_article(
    llm: LocalLLM,
    article_title: str,
    article_content: str,
    fake_summary: str,
    reliable_summary: str,
    temperature: float = 0.1,
    max_tokens: int = 300,
    naming_convention: str = "fake_reliable",
    promt_type: int = 0,
) -> ClassificationResult:
    """
    Classify an article as fake or reliable based on contrastive summaries.

    Args:
        llm: LocalLLM instance for classification
        article_title: Title of the article to classify
        article_content: Content/text of the article to classify
        fake_summary: Summary based on fake news evidence
        reliable_summary: Summary based on reliable news evidence
        temperature: LLM temperature for generation (lower = more deterministic)
        max_tokens: Maximum tokens for the response
        naming_convention: Naming convention for summaries ("fake_reliable", "type1_type2", "fake_reliable_article", "type1_type2_article")
        promt_type: Prompt type (0 = general persona, 1 = persona with background information, 2 = new article)
    Returns:
        ClassificationResult with prediction, confidence, reasoning, and raw response
    """
    classification_system = CLASSIFICATION_SYSTEMS[promt_type]
    # Apply token limits
    article_content_trimmed = _trim_tokens(article_content, 600)
    fake_summary_trimmed = _trim_tokens(fake_summary, 300)
    reliable_summary_trimmed = _trim_tokens(reliable_summary, 300)

    # Generate template with specified naming convention and random order
    template = _generate_classification_template(naming_convention, promt_type)

    # Format the prompt
    prompt = template.format(
        article_title=article_title,
        article_content=article_content_trimmed,
        fake_summary=fake_summary_trimmed,
        reliable_summary=reliable_summary_trimmed,
    )

    # Create messages for the LLM
    messages = [
        {"role": "system", "content": classification_system},
        {"role": "user", "content": prompt},
    ]

    # Get response from LLM
    response = llm.chat(
        messages=messages, temperature=temperature, max_tokens=max_tokens
    )

    # Parse the response
    return _parse_classification_response(response.text)


def _parse_classification_response(response_text: str) -> ClassificationResult:
    """
    Parse the LLM response to extract classification, confidence, and reasoning.

    Args:
        response_text: Raw response from the LLM

    Returns:
        ClassificationResult with parsed information
    """
    lines = response_text.strip().split("\n")

    prediction = "reliable"  # default
    confidence = 0.5  # default
    reasoning = "Unable to parse response"

    for line in lines:
        line = line.strip()
        if line.startswith("Classification:"):
            classification_text = line.split(":", 1)[1].strip().upper()
            if "FAKE" in classification_text:
                prediction = "fake"
            elif "RELIABLE" in classification_text:
                prediction = "reliable"
        elif line.startswith("Confidence:"):
            try:
                confidence_text = line.split(":", 1)[1].strip()
                confidence = float(confidence_text)
                # Ensure confidence is between 0 and 1
                confidence = max(0.0, min(1.0, confidence))
            except (ValueError, IndexError):
                confidence = 0.5
        elif line.startswith("Reasoning:"):
            reasoning = line.split(":", 1)[1].strip()

    return ClassificationResult(
        prediction=prediction,
        confidence=confidence,
        reasoning=reasoning,
        raw_response=response_text,
    )


def classify_article_simple(
    llm: LocalLLM,
    article_title: str,
    article_content: str,
    fake_summary: str,
    reliable_summary: str,
    naming_convention: str = "fake_reliable",
    prompt_type: int = 0,
    **kwargs,
) -> str:
    """
    Simple classification that returns only the prediction (fake/reliable).

    Args:
        llm: LocalLLM instance for classification
        article_title: Title of the article to classify
        article_content: Content/text of the article to classify
        fake_summary: Summary based on fake news evidence
        reliable_summary: Summary based on reliable news evidence
        naming_convention: Naming convention for summaries ("fake_reliable", "type1_type2", "fake_reliable_article", "type1_type2_article")
        prompt_type: Prompt type (0 = general persona, 1 = persona with background information, 2 = new article)
        **kwargs: Additional arguments passed to classify_article

    Returns:
        String: "fake" or "reliable"
    """
    result = classify_article(
        llm=llm,
        article_title=article_title,
        article_content=article_content,
        fake_summary=fake_summary,
        reliable_summary=reliable_summary,
        naming_convention=naming_convention,
        **kwargs,
    )
    return result.prediction
